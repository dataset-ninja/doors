The authors provide the **Doors: Dataset for Boulders Segmentation** - the synthetic dataset about boulders on small space bodies. It is publicly available. The dataset is meticulously curated, with carefully crafted artificial environments designed to generate large quantities of synthetic labeled images showcasing boulders on small celestial bodies. Utilizing these artificially generated environments, two distinct datasets are formed, referred to as ***ds1*** and ***ds2*** for ease of reference. Although originally tailored for specific research objectives, these datasets possess the versatility to find utility across a spectrum of applications in diverse contexts.

## Motivation

Data-driven Image Processing (IP) algorithms offer a precise, robust, and versatile alternative to traditional methods in vision-based applications concerning small objects. These algorithms find utility in navigation tasks and enable on-board autonomous capabilities.

However, the scarcity of publicly accessible labeled datasets, whether synthetic or obtained from real missions, presents a significant obstacle to the advancement of such algorithms. In the absence of these datasets, algorithm designers face two options: either creating one themselves or resorting to unsupervised learning methods. The former necessitates interdisciplinary skills, including the ability to generate realistic renderings in artificial environments, while the latter restricts the algorithm design space.

Nevertheless, developing a dataset generator is a complex endeavor that demands considerable effort, potentially diverting attention from algorithmic design. Furthermore, as exclusive access to artificial dataset generators confers strategic advantages in both industrial and research contexts, they are often kept proprietary. The same rationale applies to the datasets themselves.

## Dataset creation

In the authors' study, artificial environments are meticulously crafted to produce substantial volumes of synthetic labeled images featuring boulders on small celestial bodies. [Blender](https://www.blender.org/) is the chosen tool for this purpose, owing to its user-friendly interface, extensive prior adoption, robust support community, and open-source licensing. Leveraging these artificially generated environments, two distinct datasets are created, denoted as ***ds1*** and ***ds2*** for simplicity. While initially crafted for the specific research outlined, these datasets hold potential for broader applications across various contexts.

<img src="https://github.com/dataset-ninja/doors/assets/120389559/255a441d-55ba-439a-abb1-5908ad8e0f59" alt="image" width="600">

<span style="font-size: smaller; font-style: italic;">Pipeline used for the dataset generation.</span>

The illumination conditions are defined by the orientation and intensity of the Sun’s lamp in Blender. The intensity is handled by a random uniform value I ∈ [35, 65]. For what concern the orientation, the light is constrained to be directed from the equatorial plane of the Blender reference frame. The angle between
the camera position’s vector projection on the equatorial plane and a line-of-sight vector on the equatorial plane generated by a random uniformly generated angle θS ∈ [−90, 90] is computed. 

<img src="https://github.com/dataset-ninja/doors/assets/120389559/d0cc6d00-7f2e-4469-9633-1d9a15a5cf16" alt="image" width="600">

<span style="font-size: smaller; font-style: italic;">Example between a balanced and unbalanced distributions respectively of 5044 and 25000 samples.</span>

Using the Rock Generator add-on in Blender, a set of 30 boulder archetype shapes is generated. These are divided into three classes defined within the Rock Generator add-on, characterized by different default settings. These are the ice, river, asteroid classes. For each sample, one of the 30 boulders is randomly selected with a uniform random sample ID ∈ [0, 29] and positioned in the origin of the reference frame.

<img src="https://github.com/dataset-ninja/doors/assets/120389559/b89d1608-7084-428c-a51d-f671cdd2e7f0" alt="image" width="800">

<span style="font-size: smaller; font-style: italic;">The 30 archetype shapes that represent single instances of boulders in DS1. From top to bottom the ice, river, and asteroid classes are shown.</span>

The rendering process involves iterating through the different rows of each input file. By assigning distinct pass indices to the surface and boulders and employing Cycles as the rendering engine, its advanced ray-tracing capabilities facilitate the generation of grayscale images along with their corresponding ground truth masks delineating surface and boulders. By incorporating these masks with the specified illumination conditions, masks with shadows can also be generated for both the boulder and surface layers. Throughout rendering, the image-masks sets are produced at a resolution of 256×256 pixels. However, a post-processing pipeline is implemented to execute random cropping and introduce artificial noise.

<img src="https://github.com/dataset-ninja/doors/assets/120389559/88861f7d-3b5b-469d-bd5a-ae6f9ea6d85a" alt="image" width="800">

<span style="font-size: smaller; font-style: italic;">Post-processing pipeline used in DS1.</span>

<img src="https://github.com/dataset-ninja/doors/assets/120389559/c26324d7-705f-49ca-8b40-7b12c4e5ba2e" alt="image" width="800">

<span style="font-size: smaller; font-style: italic;">Post-processing pipeline used in DS2.</span>



